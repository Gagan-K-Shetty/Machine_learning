{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn import preprocessing \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your dataset, for example dataset = pd.read_csv(\"Your_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess your dataset and store the features into \"features\" and classes into \"lables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pass\n",
    "lables=pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size=pass    #enter the testing size, for example, 0.3 for a 70-30 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_models=[]    #list to hold all the ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model=svm.SVC()      #you can tweak the model for your needs\n",
    "svm_model.fit(X_train,y_train)\n",
    "print(\"Svm statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,svm_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,svm_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,svm_model.predict(X_test),labels=svm_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(svm_model.classes_))       #this may throw an error if your classes a integers\n",
    "ensemble_models.append(svm_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model=GaussianNB()\n",
    "naive_bayes_model.fit(X_train,y_train)\n",
    "print(\"naive_bayes statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,naive_bayes_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,naive_bayes_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,naive_bayes_model.predict(X_test),labels=naive_bayes_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(naive_bayes_model.classes_))\n",
    "ensemble_models.append(naive_bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier_model=DecisionTreeClassifier()\n",
    "DecisionTreeClassifier_model.fit(X_train,y_train)\n",
    "print(\"DecisionTree statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,DecisionTreeClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,DecisionTreeClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,DecisionTreeClassifier_model.predict(X_test),labels=DecisionTreeClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(DecisionTreeClassifier_model.classes_))\n",
    "ensemble_models.append(DecisionTreeClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier_model=RandomForestClassifier()\n",
    "RandomForestClassifier_model.fit(X_train,y_train)\n",
    "print(\"RandomForest statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,RandomForestClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,RandomForestClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,RandomForestClassifier_model.predict(X_test),labels=RandomForestClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(RandomForestClassifier_model.classes_))\n",
    "ensemble_models.append(RandomForestClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsClassifier_model=KNeighborsClassifier()\n",
    "KNeighborsClassifier_model.fit(X_train,y_train)\n",
    "print(\"KNeighbors statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,KNeighborsClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,KNeighborsClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,KNeighborsClassifier_model.predict(X_test),labels=KNeighborsClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(KNeighborsClassifier_model.classes_))\n",
    "ensemble_models.append(KNeighborsClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression_model=LogisticRegression()\n",
    "LogisticRegression_model.fit(X_train,y_train)\n",
    "print(\"LogisticRegression statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,LogisticRegression_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,LogisticRegression_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,LogisticRegression_model.predict(X_test),labels=LogisticRegression_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(LogisticRegression_model.classes_))\n",
    "ensemble_models.append(LogisticRegression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPClassifier_model=MLPClassifier()\n",
    "MLPClassifier_model.fit(X_train,y_train)\n",
    "print(\"MLPClassifier statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,MLPClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,MLPClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,MLPClassifier_model.predict(X_test),labels=MLPClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(MLPClassifier_model.classes_))\n",
    "ensemble_models.append(MLPClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier_model=MLPClassifier()\n",
    "AdaBoostClassifier_model.fit(X_train,y_train)\n",
    "print(\"AdaBoostClassifier statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,AdaBoostClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,AdaBoostClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,AdaBoostClassifier_model.predict(X_test),labels=AdaBoostClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(AdaBoostClassifier_model.classes_))\n",
    "ensemble_models.append(AdaBoostClassifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier_model=MLPClassifier()\n",
    "GradientBoostingClassifier_model.fit(X_train,y_train)\n",
    "print(\"GradientBoostingClassifier statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,GradientBoostingClassifier_model.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,GradientBoostingClassifier_model.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,GradientBoostingClassifier_model.predict(X_test),labels=GradientBoostingClassifier_model.classes_))\n",
    "print(\"Classes considered : \",\",\".join(GradientBoostingClassifier_model.classes_))\n",
    "ensemble_models.append(GradientBoostingClassifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is the ensemble logic.This is the hard voting logic,where we take the majority vote of all the classifiers.You can modify the ensemble_predict function to implement your own logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "def transpose(m):\n",
    "    return [[m[j][i] for j in range(len(m))] for i in range(len(m[0]))]\n",
    "def ensemble_predict(y,ensemble=ensemble_models):\n",
    "    predictions=[]\n",
    "    for model in ensemble:\n",
    "        predictions.append(list(model.predict(y)))\n",
    "    predictions=transpose(predictions)\n",
    "    return list(map(most_common,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,ensemble_predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,ensemble_predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,ensemble_predict(X_test),labels=ensemble_models[0].classes_))\n",
    "print(\"Classes considered : \",\",\".join(ensemble_models[0].classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use sklearn's voting classifier in a similar fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = svm.SVC(C=3)\n",
    "clf2 = GaussianNB()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "clf4 = RandomForestClassifier(bootstrap=True)\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = LogisticRegression()\n",
    "clf7 = MLPClassifier()\n",
    "clf8 = AdaBoostClassifier()\n",
    "clf9 = GradientBoostingClassifier()\n",
    "ensemble_classifier = VotingClassifier(estimators=[('svm', clf1), ('nb', clf2), ('dt', clf3),('rf',clf4),('knn',clf5),('logistic',clf6),('mlp',clf7),('ada',clf8),('GB',clf9)], voting='hard')\n",
    "ensemble_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble statistics :-\")\n",
    "print(\"Training accuracy : \",accuracy_score(y_train,ensemble_classifier.predict(X_train)))\n",
    "print(\"Testing accuracy : \",accuracy_score(y_test,ensemble_classifier.predict(X_test)))\n",
    "print(\"Confusion metrics for testing :-\\n\",confusion_matrix(y_test,ensemble_classifier.predict(X_test),labels=ensemble_classifier.classes_))\n",
    "print(\"Classes considered : \",\",\".join(ensemble_classifier.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
